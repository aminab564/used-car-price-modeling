# ğŸš— Used Car Price Modeling (CRISP-DM)

Predicting used-car prices for a mainstream dealership using linear regularization (Ridge, Lasso, Elastic Net) with a log(price) target, documented via the CRISP-DM process.

---

## ğŸ“Œ Overview

**Business Goal**  
Identify what consumers value in regular used cars (excluding vintage, exotic, and sports models) to support pricing and acquisition decisions.

**Data Task**  
Supervised regression on `log(price)` using structured features such as age, odometer, brand, condition, fuel type, cylinders, body type, and paint bucket.

**Scope**  
Focused on mainstream retail inventory:
- Price range: $3,000â€“$60,000  
- Vehicle age: â‰¤15 years

---

## ğŸ“Š Data

**Source**  
Kaggle â€œUsed Carsâ€ subset (trimmed for speed and quality).

**Key Columns Used**
- `price`, `year`, `odometer`
- `manufacturer` (one-hot encoded, ~41 categories)
- `condition`, `cylinders` (bucketed), `fuel`, `drive`, `transmission`, `size`, `type`
- `paint_color` (bucketed), `VIN` (used for deduplication)

**Excluded**
- `state`: dropped for simplicity  
- `model`: excluded due to granularity and messiness

**Filters & Cleaning**
- Retain listings priced $3kâ€“$60k and aged â‰¤15 years
- Drop â€œfinance/installmentâ€ posts (not full prices)
- Impute `odometer` by year median (train-only) + missing flag
- Parse `cylinders` â†’ impute by type median â†’ bucket into: â‰¤4, 5, 6, 8, 10+, baseline = unknown
- Fill categorical NAs/blanks as `"unknown"`
- `paint_color` â†’ collapsed into: neutrals / bright / other (baseline = other)
- One-hot encode remaining categoricals; collapse rare manufacturers to `"other"`

---

## ğŸ“ˆ CRISP-DM Summary

**Business Understanding**  
Focus on price drivers for mainstream retail; exclude placeholders and exotic listings.

**Data Understanding**  
Profiling, missingness analysis, and VIN-based duplicate detection (common in public listings).

**Data Preparation**  
Filtering, imputation, bucketing, and one-hot encoding of categorical variables.

**Modeling**  
Linear regularization methods (Ridge, Lasso, Elastic Net) applied to standardized numeric features and binary dummies. Target variable is `log(price)`.

**Evaluation**  
Metrics computed on log scale:
- MAE  
- RMSE  
- RÂ²  

---

## ğŸ”§ Modeling & Evaluation

**Why `log(price)`?**  
Stabilizes variance and interprets errors as percentage-style deviations.

**Tuning Strategy**  
- 5-fold cross-validation 
- Narrow alpha ranges to avoid convergence to OLS-like fits (minimal shrinkage)

---
Best model: **Elastic Net** (Î±=0.01, l1_ratio=0.10) â€” ties Ridge on accuracy with mild sparsity.

---

## ğŸ” Findings: What Moves Price

- **Age dominates**  
  Strong negative effect on log-priceâ€”newer cars command higher prices.

- **Powertrain matters**  
  8-cylinder configurations carry a premium versus small-cylinder baselines.  
  Gas and some â€œotherâ€ fuel types tend to discount relative to the baseline.

- **Drivetrain & condition**  
  FWD and fair condition are associated with discounts.  
  Transmission effects are present and consistent.

- **Geography**  
  `state` was excluded from the final model for simplicity.  
  Can be reintroduced (or grouped into regions) if cross-validation shows performance lift.

---

## ğŸ’¼ Business Recommendations

- **Acquisition**  
  Favor younger, lower-mileage vehicles.  
  Selectively acquire trims with favorable powertrain signals (e.g., 8-cylinder premium segments).

- **Pricing**  
  Apply stronger markdowns for fair condition or FWD where discounts are observed.  
  Maintain firmer pricing for configurations with positive effects.

- **Listing Quality**  
  Avoid installment/placeholder prices.  
  Populate missing attributesâ€”missingness correlates with lower realized prices.

- **Inventory Mix**  
  Maintain a balanced brand mix.  
  Emphasize manufacturers historically associated with stronger pricing power.

---

## ğŸ”® Next Steps

- **Model Families**  
  Try tree-based boosting (e.g., `HistGradientBoostingRegressor`, LightGBM, CatBoost) to capture nonlinearity and interactions.  
  Retain log target and compare dollar-scale MAE/RMSE (with Duan smearing).

- **Feature Set**  
  Reintroduce `state` (one-hot encoded).  
  Test light interactions (e.g., `manufacturer Ã— type`, `state Ã— drive`) via cross-validated A/B experiments.

- **Encodings**  
  For very wide categoricals (e.g., `region`, `model`), use K-fold target encoding with smoothing.

- **Transforms**  
  Explore `log1p(odometer)` and spline transformations for `age` within the â‰¤15-year scope.

- **Robustness**  
  Validate model performance on a hold-out market (different geography or time window) before deployment.
